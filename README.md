#### 27/09/2020 - повторил 2 первые главы [курса](https://stepik.org/course/54098/promo)
  ###### Основные идеи, заметки:
  ###### Глава 1
- Генерация текста:
   * через поиск похожих
   * по шаблону
   * с помощью нейросетей
- При векторном разряженном представлении документа теряется зависимость слов
- Предиктивные модели (BERT, Transformer и т.п.) не требуют размеченной выборки
- Сходство текстов можно определить как долю совпадающих путей, проходимых в графовых представлениях текстов   
- В классификации с текстами:
   * большой длины линейные модели дают основное качество
   * короткими, в зависимости от объема gold_labels:
     * малый объем - ядерные методы
     * совсем нет - системы правил

- В эксплоративном анализе применяются методы тематического регулирования: LDA, ARTM
 ###### Глава 2
- В подходе с TF-IDF не используется информация о метках документов => теряем часть информация, если она есть
#### 01/10/2020 - прочитал до
  ###### Основные идеи, заметки:
- $ R_{T}=\sum_{t=1}^{T} \ell_{t}\left(\mathbf{w}_{t}\right)-\min _{\mathbf{w}} \sum_{t=1}^{T} \ell_{t}(\mathbf{w}) $
